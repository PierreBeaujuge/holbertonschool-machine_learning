# 0x03. Optimization

## Learning Objectives

- What is a hyperparameter?
- How and why do you normalize your input data?
- What is a saddle point?
- What is stochastic gradient descent?
- What is mini-batch gradient descent?
- What is a moving average? How do you implement it?
- What is gradient descent with momentum? How do you implement it?
- What is RMSProp? How do you implement it?
- What is Adam optimization? How do you implement it?
- What is learning rate decay? How do you implement it?
- What is batch normalization? How do you implement it?

## Requirements

- Allowed editors: `vi`, `vim`, `emacs`
- All your files will be interpreted/compiled on Ubuntu 16.04 LTS using `python3` (version 3.5)
- Your files will be executed with `numpy` (version 1.15) and `tensorflow` (version 1.12)
- All your files should end with a new line
- The first line of all your files should be exactly `#!/usr/bin/env python3`
- All of your files must be executable
- A `README.md` file, at the root of the folder of the project, is mandatory
- Your code should use the `pycodestyle` style (version 2.4)
- All your modules should have documentation (`python3 -c 'print(__import__("my_module").__doc__)'`)
- All your classes should have documentation (`python3 -c 'print(__import__("my_module").MyClass.__doc__)'`)
- All your functions (inside and outside a class) should have documentation (`python3 -c 'print(__import__("my_module").my_function.__doc__)'` and `python3 -c 'print\
(__import__("my_module").MyClass.my_function.__doc__)'`)
- Unless otherwise noted, you are not allowed to import any module except import `numpy as np` and/or `import tensorflow as tf`
- You are not allowed to use the `keras` module in `tensorflow`
- You should not import any module unless it is being used

## Testing

Please use the following checkpoints for to accompany the following tensorflow main files. You do not need to push these files to GitHub. Your code will not be tested with these files.

- graph.ckpt.data-00000-of-00001
- graph.ckpt.index
- graph.ckpt.meta

## Tasks

### [0. Normalization Constants](./0-norm_constants.py)

---

### [1. Normalize](./1-normalize.py)

---

### [2. Shuffle Data](./2-shuffle_data.py)

---

### [3. Mini-Batch](./3-mini_batch.py)

---

### [4. Moving Average](./4-moving_average.py)

---

### [5. Momentum](./5-momentum.py)

---

### [6. Momentum Upgraded](./6-momentum.py)

---

### [7. RMSProp](./7-RMSProp.py)

---

### [8. RMSProp Upgraded](./8-RMSProp.py)

---

### [9. Adam](./9-Adam.py)

---

### [10. Adam Upgraded](./10-Adam.py)

---

### [11. Learning Rate Decay](./11-learning_rate_decay.py)

---

### [12. Learning Rate Decay Upgraded](./12-learning_rate_decay.py)

---

### [13. Batch Normalization](./13-batch_norm.py)

---

### [14. Batch Normalization Upgraded](./14-batch_norm.py)

---

### [15. Put it all together and what do you get?](./15-model.py)

---

## Author

- **Pierre Beaujuge** - [PierreBeaujuge](https://github.com/PierreBeaujuge)